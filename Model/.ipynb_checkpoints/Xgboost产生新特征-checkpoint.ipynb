{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.preprocessing.data import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import Tool.utils as utils\n",
    "import Tool.config as config\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(config.data_prefix_path + 'data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['user_gender_id',\n",
    "                'user_occupation_id',\n",
    "                'context_id',\n",
    "                'context_page_id',\n",
    "                'item_category_list',\n",
    "                'hour',\n",
    "                \"category_1\",\n",
    "                \"category_2\",]\n",
    "\n",
    "object_features = [\"predict_category_1\",\"predict_category_2\",\"predict_category_0\",\n",
    "                    \"predict_property_0\",\"predict_property_1\",\"predict_property_2\",\n",
    "                    \"property_1\",\"property_0\",\"property_2\",\n",
    "                    \"category_0\",\n",
    "                    'hour_and_category_1',\n",
    "                    'category_cross_0', 'category_cross_1', 'category_cross_2',\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in data.columns if c not in ['is_trade', 'instance_id','index',\n",
    "                                            'context_id', 'time', 'day','context_timestamp',\n",
    "                                            'property_list','category_list','property_predict_list','category_predict_list',\n",
    "                                            'item_category_list', 'item_property_list', 'predict_category_property',\n",
    "                                            'user_id','item_id','item_brand_id','item_city_id','user_id','shop_id',\n",
    "                                            ]\n",
    "            and c not in object_features\n",
    "            and c not in cat_features]\n",
    "target = ['is_trade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {  'booster':'gbtree', \n",
    "            'num_leaves':35, \n",
    "            'max_depth':7, \n",
    "            'eta':0.05, \n",
    "            'max_bin':425, \n",
    "            'subsample_for_bin':50000, \n",
    "            'objective':'binary:logistic', \n",
    "            'min_split_gain':0,\n",
    "            'min_child_weight':6, \n",
    "            'min_child_samples':10, \n",
    "            #'colsample_bytree':0.8,#在建立树时对特征采样的比例。缺省值为1\n",
    "            #'subsample':0.9,#用于训练模型的子样本占整个样本集合的比例。 \n",
    "            'subsample_freq':1,\n",
    "            'colsample_bytree':1, \n",
    "            'reg_lambda':4,  # 控制模型复杂度的权重值的L2正则化项参数，参数越大，模型越不容易过拟合。\n",
    "            'alpha':4,   #L1正则化 \n",
    "            'seed':2018,\n",
    "            'nthread':7, \n",
    "            'silent':True,\n",
    "            'gamma':0.2,\n",
    "            'eval_metric':'logloss'\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data[data.is_trade.notnull()]\n",
    "test = data[data.is_trade.isnull()]\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One_hot类别特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420627, 8)\n",
      "(57405, 8)\n"
     ]
    }
   ],
   "source": [
    "def getOnehotTrain(df_train,df_test,cat_features):\n",
    "    \n",
    "    df_train = df_train[cat_features]\n",
    "    df_test = df_test[cat_features]\n",
    "    \n",
    "    for cat_feature in cat_features:\n",
    "        df_train.loc[df_train[cat_feature]<0,cat_feature]=2018\n",
    "        df_test.loc[df_test[cat_feature]<0,cat_feature]=2018\n",
    "        \n",
    "    df_train = df_train[cat_features].values\n",
    "    df_test = df_test[cat_features].values\n",
    "    gc.collect()\n",
    "    \n",
    "    df_merge = np.concatenate((df_train,df_test),axis=0)\n",
    "    df_merge = df_merge.astype(np.int32)\n",
    "    \n",
    "    encoder = OneHotEncoder()\n",
    "    df_trans = encoder.fit_transform(df_merge)\n",
    "    \n",
    "    train = df_trans[:df_train.shape[0]]\n",
    "    test = df_trans[df_train.shape[0]:]\n",
    "    \n",
    "    print(train.shape)\n",
    "    print(test.shape)\n",
    "     \n",
    "    utils.save_sparse_csr('onehot_train',train)\n",
    "    utils.save_sparse_csr('onehot_test',test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '7908382889764677758;5755694407684602296'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f9b6d99765c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   2017\u001b[0m         \"\"\"\n\u001b[0;32m   2018\u001b[0m         return _transform_selected(X, self._fit_transform,\n\u001b[1;32m-> 2019\u001b[1;33m                                    self.categorical_features, copy=True)\n\u001b[0m\u001b[0;32m   2020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2021\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36m_transform_selected\u001b[1;34m(X, transform, selected, copy)\u001b[0m\n\u001b[0;32m   1807\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m     \"\"\"\n\u001b[1;32m-> 1809\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1811\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mselected\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '7908382889764677758;5755694407684602296'"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "trans = encoder.fit_transform(np.concatenate((X_train, X_val), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost新特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train[train.day < 24]\n",
    "X_val = train[train.day == 24]\n",
    "    \n",
    "\n",
    "train = X_train[features].values\n",
    "val = X_val[features].values\n",
    "train_label = X_train[target].values.ravel()\n",
    "val_label = X_val[target].values.ravel()\n",
    "\n",
    "xgb_train = xgb.DMatrix(train, train_label)\n",
    "xgb_val = xgb.DMatrix(val, val_label)\n",
    "    \n",
    "watchlist = [(xgb_train, 'train'),(xgb_val, 'val')]\n",
    "\n",
    "del X_train,X_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.648024\tval-logloss:0.647773\n",
      "Multiple eval metrics have been passed: 'val-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until val-logloss hasn't improved in 50 rounds.\n",
      "[1]\ttrain-logloss:0.6072\tval-logloss:0.606728\n",
      "[2]\ttrain-logloss:0.570103\tval-logloss:0.56941\n",
      "[3]\ttrain-logloss:0.536261\tval-logloss:0.535388\n",
      "[4]\ttrain-logloss:0.50529\tval-logloss:0.504233\n",
      "[5]\ttrain-logloss:0.476862\tval-logloss:0.475627\n",
      "[6]\ttrain-logloss:0.450702\tval-logloss:0.449298\n",
      "[7]\ttrain-logloss:0.426575\tval-logloss:0.425012\n",
      "[8]\ttrain-logloss:0.404277\tval-logloss:0.402551\n",
      "[9]\ttrain-logloss:0.383632\tval-logloss:0.381774\n",
      "[10]\ttrain-logloss:0.364486\tval-logloss:0.362419\n",
      "[11]\ttrain-logloss:0.346709\tval-logloss:0.344502\n",
      "[12]\ttrain-logloss:0.330179\tval-logloss:0.327853\n",
      "[13]\ttrain-logloss:0.314792\tval-logloss:0.312328\n",
      "[14]\ttrain-logloss:0.300453\tval-logloss:0.297854\n",
      "[15]\ttrain-logloss:0.287075\tval-logloss:0.284311\n",
      "[16]\ttrain-logloss:0.274589\tval-logloss:0.271699\n",
      "[17]\ttrain-logloss:0.26292\tval-logloss:0.259913\n",
      "[18]\ttrain-logloss:0.252011\tval-logloss:0.248892\n",
      "[19]\ttrain-logloss:0.241796\tval-logloss:0.238582\n",
      "[20]\ttrain-logloss:0.232236\tval-logloss:0.22892\n",
      "[21]\ttrain-logloss:0.223286\tval-logloss:0.219844\n",
      "[22]\ttrain-logloss:0.214899\tval-logloss:0.211356\n",
      "[23]\ttrain-logloss:0.207035\tval-logloss:0.203368\n",
      "[24]\ttrain-logloss:0.199657\tval-logloss:0.195902\n",
      "[25]\ttrain-logloss:0.192736\tval-logloss:0.188877\n",
      "[26]\ttrain-logloss:0.186237\tval-logloss:0.182299\n",
      "[27]\ttrain-logloss:0.18014\tval-logloss:0.176113\n",
      "[28]\ttrain-logloss:0.174416\tval-logloss:0.17032\n",
      "[29]\ttrain-logloss:0.16904\tval-logloss:0.164816\n",
      "[30]\ttrain-logloss:0.163988\tval-logloss:0.159694\n",
      "[31]\ttrain-logloss:0.15924\tval-logloss:0.154885\n",
      "[32]\ttrain-logloss:0.154785\tval-logloss:0.150326\n",
      "[33]\ttrain-logloss:0.150603\tval-logloss:0.146054\n",
      "[34]\ttrain-logloss:0.146662\tval-logloss:0.142037\n",
      "[35]\ttrain-logloss:0.142964\tval-logloss:0.138255\n",
      "[36]\ttrain-logloss:0.139488\tval-logloss:0.134732\n",
      "[37]\ttrain-logloss:0.136213\tval-logloss:0.131411\n",
      "[38]\ttrain-logloss:0.13315\tval-logloss:0.128266\n",
      "[39]\ttrain-logloss:0.130258\tval-logloss:0.125323\n",
      "[40]\ttrain-logloss:0.127551\tval-logloss:0.12255\n",
      "[41]\ttrain-logloss:0.125002\tval-logloss:0.119944\n",
      "[42]\ttrain-logloss:0.122607\tval-logloss:0.117513\n",
      "[43]\ttrain-logloss:0.120353\tval-logloss:0.115228\n",
      "[44]\ttrain-logloss:0.118239\tval-logloss:0.113079\n",
      "[45]\ttrain-logloss:0.11625\tval-logloss:0.111042\n",
      "[46]\ttrain-logloss:0.114384\tval-logloss:0.109125\n",
      "[47]\ttrain-logloss:0.112627\tval-logloss:0.10733\n",
      "[48]\ttrain-logloss:0.110984\tval-logloss:0.105649\n",
      "[49]\ttrain-logloss:0.109427\tval-logloss:0.104057\n",
      "[50]\ttrain-logloss:0.107976\tval-logloss:0.102562\n",
      "[51]\ttrain-logloss:0.106601\tval-logloss:0.101176\n",
      "[52]\ttrain-logloss:0.105316\tval-logloss:0.099857\n",
      "[53]\ttrain-logloss:0.104104\tval-logloss:0.098633\n",
      "[54]\ttrain-logloss:0.102973\tval-logloss:0.097473\n",
      "[55]\ttrain-logloss:0.101898\tval-logloss:0.096392\n",
      "[56]\ttrain-logloss:0.100894\tval-logloss:0.095374\n",
      "[57]\ttrain-logloss:0.099948\tval-logloss:0.094416\n",
      "[58]\ttrain-logloss:0.099064\tval-logloss:0.093527\n",
      "[59]\ttrain-logloss:0.098223\tval-logloss:0.0927\n",
      "[60]\ttrain-logloss:0.097432\tval-logloss:0.091922\n",
      "[61]\ttrain-logloss:0.096691\tval-logloss:0.091189\n",
      "[62]\ttrain-logloss:0.095993\tval-logloss:0.090509\n",
      "[63]\ttrain-logloss:0.095329\tval-logloss:0.08985\n",
      "[64]\ttrain-logloss:0.094718\tval-logloss:0.089252\n",
      "[65]\ttrain-logloss:0.094146\tval-logloss:0.088684\n",
      "[66]\ttrain-logloss:0.0936\tval-logloss:0.088147\n",
      "[67]\ttrain-logloss:0.093082\tval-logloss:0.087645\n",
      "[68]\ttrain-logloss:0.092588\tval-logloss:0.087183\n",
      "[69]\ttrain-logloss:0.092114\tval-logloss:0.086738\n",
      "[70]\ttrain-logloss:0.091668\tval-logloss:0.086322\n",
      "[71]\ttrain-logloss:0.09126\tval-logloss:0.085932\n",
      "[72]\ttrain-logloss:0.090867\tval-logloss:0.085591\n",
      "[73]\ttrain-logloss:0.090474\tval-logloss:0.085252\n",
      "[74]\ttrain-logloss:0.09013\tval-logloss:0.084946\n",
      "[75]\ttrain-logloss:0.089781\tval-logloss:0.084646\n",
      "[76]\ttrain-logloss:0.089457\tval-logloss:0.084374\n",
      "[77]\ttrain-logloss:0.089152\tval-logloss:0.084109\n",
      "[78]\ttrain-logloss:0.08886\tval-logloss:0.083877\n",
      "[79]\ttrain-logloss:0.088576\tval-logloss:0.083655\n",
      "[80]\ttrain-logloss:0.088311\tval-logloss:0.083432\n",
      "[81]\ttrain-logloss:0.088052\tval-logloss:0.083237\n",
      "[82]\ttrain-logloss:0.087801\tval-logloss:0.083055\n",
      "[83]\ttrain-logloss:0.087571\tval-logloss:0.082878\n",
      "[84]\ttrain-logloss:0.087345\tval-logloss:0.082714\n",
      "[85]\ttrain-logloss:0.087137\tval-logloss:0.082558\n",
      "[86]\ttrain-logloss:0.086925\tval-logloss:0.082423\n",
      "[87]\ttrain-logloss:0.086723\tval-logloss:0.08229\n",
      "[88]\ttrain-logloss:0.086542\tval-logloss:0.082169\n",
      "[89]\ttrain-logloss:0.086369\tval-logloss:0.082034\n",
      "[90]\ttrain-logloss:0.086204\tval-logloss:0.081919\n",
      "[91]\ttrain-logloss:0.086012\tval-logloss:0.081794\n",
      "[92]\ttrain-logloss:0.085844\tval-logloss:0.0817\n",
      "[93]\ttrain-logloss:0.085684\tval-logloss:0.081592\n",
      "[94]\ttrain-logloss:0.085535\tval-logloss:0.08151\n",
      "[95]\ttrain-logloss:0.085388\tval-logloss:0.081404\n",
      "[96]\ttrain-logloss:0.085245\tval-logloss:0.081329\n",
      "[97]\ttrain-logloss:0.085121\tval-logloss:0.081249\n",
      "[98]\ttrain-logloss:0.08498\tval-logloss:0.081171\n",
      "[99]\ttrain-logloss:0.084829\tval-logloss:0.081105\n",
      "[100]\ttrain-logloss:0.084713\tval-logloss:0.08104\n",
      "[101]\ttrain-logloss:0.084579\tval-logloss:0.080979\n",
      "[102]\ttrain-logloss:0.084454\tval-logloss:0.080912\n",
      "[103]\ttrain-logloss:0.084348\tval-logloss:0.080863\n",
      "[104]\ttrain-logloss:0.084241\tval-logloss:0.080807\n",
      "[105]\ttrain-logloss:0.084134\tval-logloss:0.080764\n",
      "[106]\ttrain-logloss:0.084018\tval-logloss:0.080701\n",
      "[107]\ttrain-logloss:0.083921\tval-logloss:0.080648\n",
      "[108]\ttrain-logloss:0.083824\tval-logloss:0.080592\n",
      "[109]\ttrain-logloss:0.083734\tval-logloss:0.080554\n",
      "[110]\ttrain-logloss:0.083607\tval-logloss:0.080512\n",
      "[111]\ttrain-logloss:0.083533\tval-logloss:0.080466\n",
      "[112]\ttrain-logloss:0.083452\tval-logloss:0.080436\n",
      "[113]\ttrain-logloss:0.083366\tval-logloss:0.080401\n",
      "[114]\ttrain-logloss:0.083281\tval-logloss:0.080374\n",
      "[115]\ttrain-logloss:0.083215\tval-logloss:0.08034\n",
      "[116]\ttrain-logloss:0.083135\tval-logloss:0.080312\n",
      "[117]\ttrain-logloss:0.083062\tval-logloss:0.080289\n",
      "[118]\ttrain-logloss:0.082957\tval-logloss:0.080249\n",
      "[119]\ttrain-logloss:0.082871\tval-logloss:0.080234\n",
      "[120]\ttrain-logloss:0.082789\tval-logloss:0.08022\n",
      "[121]\ttrain-logloss:0.082714\tval-logloss:0.080203\n",
      "[122]\ttrain-logloss:0.082645\tval-logloss:0.080175\n",
      "[123]\ttrain-logloss:0.08258\tval-logloss:0.080158\n",
      "[124]\ttrain-logloss:0.082487\tval-logloss:0.080144\n",
      "[125]\ttrain-logloss:0.082404\tval-logloss:0.080129\n",
      "[126]\ttrain-logloss:0.082343\tval-logloss:0.080119\n",
      "[127]\ttrain-logloss:0.082278\tval-logloss:0.080092\n",
      "[128]\ttrain-logloss:0.082196\tval-logloss:0.080087\n",
      "[129]\ttrain-logloss:0.08213\tval-logloss:0.080076\n",
      "[130]\ttrain-logloss:0.082066\tval-logloss:0.080053\n",
      "[131]\ttrain-logloss:0.082007\tval-logloss:0.080042\n",
      "[132]\ttrain-logloss:0.081926\tval-logloss:0.08003\n",
      "[133]\ttrain-logloss:0.081871\tval-logloss:0.080022\n",
      "[134]\ttrain-logloss:0.081814\tval-logloss:0.080021\n",
      "[135]\ttrain-logloss:0.081759\tval-logloss:0.080013\n",
      "[136]\ttrain-logloss:0.081703\tval-logloss:0.080003\n",
      "[137]\ttrain-logloss:0.081639\tval-logloss:0.080006\n",
      "[138]\ttrain-logloss:0.081546\tval-logloss:0.080002\n",
      "[139]\ttrain-logloss:0.081481\tval-logloss:0.079983\n",
      "[140]\ttrain-logloss:0.081406\tval-logloss:0.07997\n",
      "[141]\ttrain-logloss:0.081331\tval-logloss:0.079967\n",
      "[142]\ttrain-logloss:0.081269\tval-logloss:0.079962\n",
      "[143]\ttrain-logloss:0.081194\tval-logloss:0.079946\n",
      "[144]\ttrain-logloss:0.081122\tval-logloss:0.079943\n",
      "[145]\ttrain-logloss:0.081047\tval-logloss:0.079929\n",
      "[146]\ttrain-logloss:0.080979\tval-logloss:0.079924\n",
      "[147]\ttrain-logloss:0.080938\tval-logloss:0.079914\n",
      "[148]\ttrain-logloss:0.080902\tval-logloss:0.07991\n",
      "[149]\ttrain-logloss:0.080822\tval-logloss:0.0799\n",
      "[150]\ttrain-logloss:0.080761\tval-logloss:0.079906\n",
      "[151]\ttrain-logloss:0.080675\tval-logloss:0.079897\n",
      "[152]\ttrain-logloss:0.080616\tval-logloss:0.079886\n",
      "[153]\ttrain-logloss:0.080558\tval-logloss:0.079878\n",
      "[154]\ttrain-logloss:0.080506\tval-logloss:0.07988\n",
      "[155]\ttrain-logloss:0.080418\tval-logloss:0.079867\n",
      "[156]\ttrain-logloss:0.080365\tval-logloss:0.079859\n",
      "[157]\ttrain-logloss:0.080306\tval-logloss:0.07985\n",
      "[158]\ttrain-logloss:0.08023\tval-logloss:0.079834\n",
      "[159]\ttrain-logloss:0.08019\tval-logloss:0.079831\n",
      "[160]\ttrain-logloss:0.080152\tval-logloss:0.079824\n",
      "[161]\ttrain-logloss:0.080114\tval-logloss:0.079815\n",
      "[162]\ttrain-logloss:0.080021\tval-logloss:0.079802\n",
      "[163]\ttrain-logloss:0.07995\tval-logloss:0.079812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\ttrain-logloss:0.079898\tval-logloss:0.079813\n",
      "[165]\ttrain-logloss:0.07988\tval-logloss:0.079806\n",
      "[166]\ttrain-logloss:0.079811\tval-logloss:0.079799\n",
      "[167]\ttrain-logloss:0.079773\tval-logloss:0.079794\n",
      "[168]\ttrain-logloss:0.079726\tval-logloss:0.079784\n",
      "[169]\ttrain-logloss:0.079665\tval-logloss:0.079773\n",
      "[170]\ttrain-logloss:0.079604\tval-logloss:0.079774\n",
      "[171]\ttrain-logloss:0.07956\tval-logloss:0.079766\n",
      "[172]\ttrain-logloss:0.07948\tval-logloss:0.079761\n",
      "[173]\ttrain-logloss:0.079436\tval-logloss:0.079764\n",
      "[174]\ttrain-logloss:0.07938\tval-logloss:0.07977\n",
      "[175]\ttrain-logloss:0.079355\tval-logloss:0.079772\n",
      "[176]\ttrain-logloss:0.079328\tval-logloss:0.079769\n",
      "[177]\ttrain-logloss:0.079261\tval-logloss:0.07977\n",
      "[178]\ttrain-logloss:0.079216\tval-logloss:0.079766\n",
      "[179]\ttrain-logloss:0.079186\tval-logloss:0.079761\n",
      "[180]\ttrain-logloss:0.079146\tval-logloss:0.079753\n",
      "[181]\ttrain-logloss:0.079072\tval-logloss:0.079753\n",
      "[182]\ttrain-logloss:0.079015\tval-logloss:0.079758\n",
      "[183]\ttrain-logloss:0.07898\tval-logloss:0.079758\n",
      "[184]\ttrain-logloss:0.07892\tval-logloss:0.07975\n",
      "[185]\ttrain-logloss:0.078884\tval-logloss:0.079756\n",
      "[186]\ttrain-logloss:0.078846\tval-logloss:0.079762\n",
      "[187]\ttrain-logloss:0.07881\tval-logloss:0.079763\n",
      "[188]\ttrain-logloss:0.078726\tval-logloss:0.079759\n",
      "[189]\ttrain-logloss:0.078691\tval-logloss:0.079757\n",
      "[190]\ttrain-logloss:0.078668\tval-logloss:0.079761\n",
      "[191]\ttrain-logloss:0.078649\tval-logloss:0.079759\n",
      "[192]\ttrain-logloss:0.0786\tval-logloss:0.079757\n",
      "[193]\ttrain-logloss:0.078587\tval-logloss:0.07975\n",
      "[194]\ttrain-logloss:0.078568\tval-logloss:0.07975\n",
      "[195]\ttrain-logloss:0.078515\tval-logloss:0.079758\n",
      "[196]\ttrain-logloss:0.078436\tval-logloss:0.079754\n",
      "[197]\ttrain-logloss:0.078398\tval-logloss:0.079756\n",
      "[198]\ttrain-logloss:0.078361\tval-logloss:0.079751\n",
      "[199]\ttrain-logloss:0.078326\tval-logloss:0.079748\n",
      "[200]\ttrain-logloss:0.078291\tval-logloss:0.079752\n",
      "[201]\ttrain-logloss:0.078263\tval-logloss:0.079747\n",
      "[202]\ttrain-logloss:0.078227\tval-logloss:0.079753\n",
      "[203]\ttrain-logloss:0.078202\tval-logloss:0.07975\n",
      "[204]\ttrain-logloss:0.078178\tval-logloss:0.079741\n",
      "[205]\ttrain-logloss:0.078142\tval-logloss:0.079754\n",
      "[206]\ttrain-logloss:0.078092\tval-logloss:0.079755\n",
      "[207]\ttrain-logloss:0.078071\tval-logloss:0.079754\n",
      "[208]\ttrain-logloss:0.078042\tval-logloss:0.079755\n",
      "[209]\ttrain-logloss:0.07802\tval-logloss:0.079754\n",
      "[210]\ttrain-logloss:0.077989\tval-logloss:0.079758\n",
      "[211]\ttrain-logloss:0.077931\tval-logloss:0.079754\n",
      "[212]\ttrain-logloss:0.077903\tval-logloss:0.079752\n",
      "[213]\ttrain-logloss:0.077855\tval-logloss:0.079764\n",
      "[214]\ttrain-logloss:0.077827\tval-logloss:0.079761\n",
      "[215]\ttrain-logloss:0.077799\tval-logloss:0.079761\n",
      "[216]\ttrain-logloss:0.077723\tval-logloss:0.079763\n",
      "[217]\ttrain-logloss:0.077694\tval-logloss:0.079766\n",
      "[218]\ttrain-logloss:0.077675\tval-logloss:0.079769\n",
      "[219]\ttrain-logloss:0.077653\tval-logloss:0.079769\n",
      "[220]\ttrain-logloss:0.07761\tval-logloss:0.079762\n",
      "[221]\ttrain-logloss:0.077539\tval-logloss:0.079759\n",
      "[222]\ttrain-logloss:0.077504\tval-logloss:0.079762\n",
      "[223]\ttrain-logloss:0.077461\tval-logloss:0.079769\n",
      "[224]\ttrain-logloss:0.077443\tval-logloss:0.079772\n",
      "[225]\ttrain-logloss:0.077429\tval-logloss:0.079771\n",
      "[226]\ttrain-logloss:0.077374\tval-logloss:0.079778\n",
      "[227]\ttrain-logloss:0.077343\tval-logloss:0.079778\n",
      "[228]\ttrain-logloss:0.077306\tval-logloss:0.079782\n",
      "[229]\ttrain-logloss:0.077263\tval-logloss:0.079774\n",
      "[230]\ttrain-logloss:0.077241\tval-logloss:0.079777\n",
      "[231]\ttrain-logloss:0.077217\tval-logloss:0.079772\n",
      "[232]\ttrain-logloss:0.077168\tval-logloss:0.079762\n",
      "[233]\ttrain-logloss:0.077134\tval-logloss:0.079751\n",
      "[234]\ttrain-logloss:0.077098\tval-logloss:0.07975\n",
      "[235]\ttrain-logloss:0.077078\tval-logloss:0.07975\n",
      "[236]\ttrain-logloss:0.077021\tval-logloss:0.079745\n",
      "[237]\ttrain-logloss:0.07699\tval-logloss:0.079749\n",
      "[238]\ttrain-logloss:0.076944\tval-logloss:0.079742\n",
      "[239]\ttrain-logloss:0.07687\tval-logloss:0.079744\n",
      "[240]\ttrain-logloss:0.076843\tval-logloss:0.079735\n",
      "[241]\ttrain-logloss:0.076821\tval-logloss:0.079743\n",
      "[242]\ttrain-logloss:0.076771\tval-logloss:0.079743\n",
      "[243]\ttrain-logloss:0.076754\tval-logloss:0.079745\n",
      "[244]\ttrain-logloss:0.076719\tval-logloss:0.079742\n",
      "[245]\ttrain-logloss:0.07665\tval-logloss:0.079729\n",
      "[246]\ttrain-logloss:0.076592\tval-logloss:0.079731\n",
      "[247]\ttrain-logloss:0.076568\tval-logloss:0.079729\n",
      "[248]\ttrain-logloss:0.076504\tval-logloss:0.079725\n",
      "[249]\ttrain-logloss:0.076476\tval-logloss:0.07973\n",
      "[250]\ttrain-logloss:0.076445\tval-logloss:0.079731\n",
      "[251]\ttrain-logloss:0.076405\tval-logloss:0.079714\n",
      "[252]\ttrain-logloss:0.076375\tval-logloss:0.079715\n",
      "[253]\ttrain-logloss:0.076307\tval-logloss:0.07972\n",
      "[254]\ttrain-logloss:0.076223\tval-logloss:0.079719\n",
      "[255]\ttrain-logloss:0.076194\tval-logloss:0.079715\n",
      "[256]\ttrain-logloss:0.076164\tval-logloss:0.079717\n",
      "[257]\ttrain-logloss:0.076118\tval-logloss:0.079713\n",
      "[258]\ttrain-logloss:0.076092\tval-logloss:0.079715\n",
      "[259]\ttrain-logloss:0.076057\tval-logloss:0.079704\n",
      "[260]\ttrain-logloss:0.076035\tval-logloss:0.079706\n",
      "[261]\ttrain-logloss:0.075965\tval-logloss:0.079694\n",
      "[262]\ttrain-logloss:0.075949\tval-logloss:0.079697\n",
      "[263]\ttrain-logloss:0.075927\tval-logloss:0.079704\n",
      "[264]\ttrain-logloss:0.075914\tval-logloss:0.079702\n",
      "[265]\ttrain-logloss:0.075835\tval-logloss:0.079693\n",
      "[266]\ttrain-logloss:0.075803\tval-logloss:0.079695\n",
      "[267]\ttrain-logloss:0.075751\tval-logloss:0.079695\n",
      "[268]\ttrain-logloss:0.075703\tval-logloss:0.079694\n",
      "[269]\ttrain-logloss:0.075665\tval-logloss:0.079698\n",
      "[270]\ttrain-logloss:0.075609\tval-logloss:0.079695\n",
      "[271]\ttrain-logloss:0.075541\tval-logloss:0.079698\n",
      "[272]\ttrain-logloss:0.075485\tval-logloss:0.079684\n",
      "[273]\ttrain-logloss:0.075461\tval-logloss:0.079686\n",
      "[274]\ttrain-logloss:0.075434\tval-logloss:0.079681\n",
      "[275]\ttrain-logloss:0.075417\tval-logloss:0.079677\n",
      "[276]\ttrain-logloss:0.075396\tval-logloss:0.079675\n",
      "[277]\ttrain-logloss:0.075334\tval-logloss:0.079674\n",
      "[278]\ttrain-logloss:0.075306\tval-logloss:0.079673\n",
      "[279]\ttrain-logloss:0.075242\tval-logloss:0.079684\n",
      "[280]\ttrain-logloss:0.075177\tval-logloss:0.079681\n",
      "[281]\ttrain-logloss:0.075129\tval-logloss:0.079688\n",
      "[282]\ttrain-logloss:0.075069\tval-logloss:0.07969\n",
      "[283]\ttrain-logloss:0.075017\tval-logloss:0.07969\n",
      "[284]\ttrain-logloss:0.074973\tval-logloss:0.079693\n",
      "[285]\ttrain-logloss:0.074949\tval-logloss:0.07969\n",
      "[286]\ttrain-logloss:0.074929\tval-logloss:0.079692\n",
      "[287]\ttrain-logloss:0.07491\tval-logloss:0.079691\n",
      "[288]\ttrain-logloss:0.074888\tval-logloss:0.079694\n",
      "[289]\ttrain-logloss:0.074872\tval-logloss:0.079694\n",
      "[290]\ttrain-logloss:0.074819\tval-logloss:0.079691\n",
      "[291]\ttrain-logloss:0.074761\tval-logloss:0.079693\n",
      "[292]\ttrain-logloss:0.074743\tval-logloss:0.079697\n",
      "[293]\ttrain-logloss:0.074704\tval-logloss:0.079697\n",
      "[294]\ttrain-logloss:0.074656\tval-logloss:0.079706\n",
      "[295]\ttrain-logloss:0.074596\tval-logloss:0.079712\n",
      "[296]\ttrain-logloss:0.074569\tval-logloss:0.07971\n",
      "[297]\ttrain-logloss:0.074555\tval-logloss:0.079713\n",
      "[298]\ttrain-logloss:0.074531\tval-logloss:0.079709\n",
      "[299]\ttrain-logloss:0.074501\tval-logloss:0.079708\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params, xgb_train, 300, watchlist,early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-66e704e642c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_leaves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_leaves\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_leaves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_leaves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_leaves = model.predict(xgb_train, pred_leaf=True)\n",
    "val_leaves = model.predict(xgb_val, pred_leaf=True)\n",
    "(train_rows, cols) = train_leaves.shape\n",
    "\n",
    "print(train_leaves.shape)\n",
    "print(val_leaves.shape)\n",
    "    \n",
    "del xgb_train,xgb_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420629, 76)\n",
      "(57406, 76)\n"
     ]
    }
   ],
   "source": [
    "one_hot_train = utils.load_sparse_csr('tree_leaves_train.npz')\n",
    "one_hot_val = utils.load_sparse_csr('onehot_val.npz')\n",
    "print(one_hot_train.shape)\n",
    "print(one_hot_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478035, 13575)\n"
     ]
    }
   ],
   "source": [
    "gbdtenc = OneHotEncoder()\n",
    "trans = gbdtenc.fit_transform(np.concatenate((train_leaves, val_leaves), axis=0))\n",
    "print(trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8a4bd7ccd0be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrans_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtrain_rows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrans_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_rows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mone_hot_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mtrans\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_leaves\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trans' is not defined"
     ]
    }
   ],
   "source": [
    "trans_train = hstack([trans[:train_rows,:],one_hot_train])\n",
    "trans_val = hstack([trans[train_rows:,:],one_hot_val])\n",
    "del trans,train_leaves,val_leaves\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nutils.save_sparse_csr('xgboost_onehot_train_non24', trans[:train_rows,:])\\nutils.save_sparse_csr('xgboost_onehot_val_non24', trans[train_rows:,:])\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "utils.save_sparse_csr('xgboost_onehot_train_non24', trans[:train_rows,:])\n",
    "utils.save_sparse_csr('xgboost_onehot_val_non24', trans[train_rows:,:])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0814638101058\n",
      "0.0806875148726\n",
      "0.702671568724\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "lr = LogisticRegression(n_jobs=6,C=0.0004)\n",
    "    \n",
    "lr.fit(trans_train, train_label)\n",
    "    \n",
    "y_train_pred = lr.predict_proba(trans_train)[:,1]\n",
    "train_log = log_loss(train_label,y_train_pred)\n",
    "    \n",
    "y_val_pred = lr.predict_proba(trans_val)[:,1]\n",
    "val_log = log_loss(val_label,y_val_pred)\n",
    "    \n",
    "print(train_log)\n",
    "print(val_log)\n",
    "print(roc_auc_score(val_label,y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FM_FTRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = FM_FTRL(\n",
    "    alpha=0.05,   #w0和w的FTRL超参数alpha\n",
    "    beta=3,   #w0和w的FTRL超参数beta\n",
    "    L1=0.1,    #w0和w的L1正则\n",
    "    L2=10,    #w0和w的L2正则\n",
    "    D=train.shape[1], \n",
    "    \n",
    "    alpha_fm=0.05, #v的FTRL超参数alpha\n",
    "    L2_fm=5, #v的L2正则\n",
    "    \n",
    "    init_fm=0.01,\n",
    "    D_fm=8, \n",
    "    e_noise=0.01, \n",
    "    iters=3, \n",
    "    inv_link=\"sigmoid\", \n",
    "    threads=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(trans_train,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = clf.predict(trans_train)\n",
    "y_val = clf.predict(trans_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_logloss: \"+ str(log_loss(train_label,y_train)))\n",
    "print(\"val_logloss: \"+ str(log_loss(val_label,y_val)))\n",
    "\n",
    "print(\"train_auc: \"+ str(roc_auc_score(train_label,y_train)))\n",
    "print(\"val_auc: \"+ str(roc_auc_score(val_label,y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(PATH + \"Train0403.csv\")\n",
    "df_test = pd.read_csv(PATH + \"Test0403.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= [ feature for feature in df_train.head(0) if feature not in ['instance_id','item_id','item_category_list','item_property_list',\\\n",
    "                                                         'item_brand_id','item_city_id','user_id',\\\n",
    "                                                         'context_id','context_timestamp','predict_category_property','shop_id',\\\n",
    "                                                         'time','day','index_x','index_y','item_category_list_isPreTrue',\\\n",
    "                                                         'item_brand_id_PurchaseRate','item_city_id_PurchaseRate','hour_PurchaseRate',\\\n",
    "                                                         'is_trade',\\\n",
    "                                                         'user_gender_id_user_id_cnt','user_gender_id_user_id_prob','user_age_level_user_id_cnt','user_age_level_user_id_prob','user_occupation_id_user_id_cnt','user_occupation_id_user_id_prob',\\\n",
    "                                                         'item_property_list_shop_id_cnt','item_property_list_shop_id_prob','item_property_list_shop_review_num_level_cnt','item_property_list_shop_review_num_level_prob','item_property_list_shop_star_level_cnt','item_property_list_shop_star_level_prob',\\\n",
    "                                                         'item_brand_id_item_id_cnt','item_brand_id_item_id_prob','item_city_id_item_id_cnt','item_city_id_item_id_prob','item_price_level_item_id_cnt','item_price_level_item_id_prob','item_sales_level_item_id_cnt','item_sales_level_item_id_prob',\\\n",
    "                                                         'item_collected_level_item_id_cnt','item_collected_level_item_id_prob','item_pv_level_item_id_cnt','item_pv_level_item_id_prob',\\\n",
    "                                                         'item_id_shop_id_cnt','item_id_shop_id_prob','item_id_shop_review_num_level_cnt','item_id_shop_review_num_level_prob','item_id_shop_star_level_cnt','item_id_shop_star_level_prob',\\\n",
    "                                                         'item_id_user_id_cnt','item_id_user_id_prob']\\\n",
    "                                        and not feature.endswith('0') and not feature.endswith('var')\n",
    "                                        and feature not in cat_features]\n",
    "target = 'is_trade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df_train[features].values\n",
    "test = df_test[features].values\n",
    "train_label =df_train[target].values.ravel()\n",
    "\n",
    "xgb_train = xgb.DMatrix(train, train_label)\n",
    "xgb_test = xgb.DMatrix(test)\n",
    "    \n",
    "watchlist = [(xgb_train, 'train')]\n",
    "del train,test,df_train\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.57895\n",
      "Will train until train-auc hasn't improved in 50 rounds.\n",
      "[1]\ttrain-auc:0.631263\n",
      "[2]\ttrain-auc:0.632452\n",
      "[3]\ttrain-auc:0.647459\n",
      "[4]\ttrain-auc:0.646546\n",
      "[5]\ttrain-auc:0.647965\n",
      "[6]\ttrain-auc:0.64889\n",
      "[7]\ttrain-auc:0.653438\n",
      "[8]\ttrain-auc:0.655599\n",
      "[9]\ttrain-auc:0.655248\n",
      "[10]\ttrain-auc:0.655015\n",
      "[11]\ttrain-auc:0.656357\n",
      "[12]\ttrain-auc:0.657418\n",
      "[13]\ttrain-auc:0.657121\n",
      "[14]\ttrain-auc:0.657152\n",
      "[15]\ttrain-auc:0.658859\n",
      "[16]\ttrain-auc:0.659382\n",
      "[17]\ttrain-auc:0.662484\n",
      "[18]\ttrain-auc:0.664326\n",
      "[19]\ttrain-auc:0.664309\n",
      "[20]\ttrain-auc:0.665625\n",
      "[21]\ttrain-auc:0.666368\n",
      "[22]\ttrain-auc:0.66675\n",
      "[23]\ttrain-auc:0.666515\n",
      "[24]\ttrain-auc:0.666906\n",
      "[25]\ttrain-auc:0.667971\n",
      "[26]\ttrain-auc:0.668208\n",
      "[27]\ttrain-auc:0.669743\n",
      "[28]\ttrain-auc:0.670695\n",
      "[29]\ttrain-auc:0.672612\n",
      "[30]\ttrain-auc:0.672692\n",
      "[31]\ttrain-auc:0.673213\n",
      "[32]\ttrain-auc:0.674004\n",
      "[33]\ttrain-auc:0.675088\n",
      "[34]\ttrain-auc:0.676075\n",
      "[35]\ttrain-auc:0.676554\n",
      "[36]\ttrain-auc:0.677614\n",
      "[37]\ttrain-auc:0.678682\n",
      "[38]\ttrain-auc:0.679251\n",
      "[39]\ttrain-auc:0.680369\n",
      "[40]\ttrain-auc:0.680872\n",
      "[41]\ttrain-auc:0.681288\n",
      "[42]\ttrain-auc:0.681379\n",
      "[43]\ttrain-auc:0.683973\n",
      "[44]\ttrain-auc:0.68483\n",
      "[45]\ttrain-auc:0.685492\n",
      "[46]\ttrain-auc:0.686053\n",
      "[47]\ttrain-auc:0.686742\n",
      "[48]\ttrain-auc:0.688594\n",
      "[49]\ttrain-auc:0.689266\n",
      "[50]\ttrain-auc:0.690075\n",
      "[51]\ttrain-auc:0.69134\n",
      "[52]\ttrain-auc:0.69281\n",
      "[53]\ttrain-auc:0.694407\n",
      "[54]\ttrain-auc:0.695349\n",
      "[55]\ttrain-auc:0.696893\n",
      "[56]\ttrain-auc:0.697559\n",
      "[57]\ttrain-auc:0.69861\n",
      "[58]\ttrain-auc:0.699827\n",
      "[59]\ttrain-auc:0.700574\n",
      "[60]\ttrain-auc:0.701918\n",
      "[61]\ttrain-auc:0.702663\n",
      "[62]\ttrain-auc:0.703251\n",
      "[63]\ttrain-auc:0.704616\n",
      "[64]\ttrain-auc:0.705892\n",
      "[65]\ttrain-auc:0.707283\n",
      "[66]\ttrain-auc:0.708033\n",
      "[67]\ttrain-auc:0.709647\n",
      "[68]\ttrain-auc:0.71131\n",
      "[69]\ttrain-auc:0.712199\n",
      "[70]\ttrain-auc:0.713175\n",
      "[71]\ttrain-auc:0.714434\n",
      "[72]\ttrain-auc:0.715433\n",
      "[73]\ttrain-auc:0.716804\n",
      "[74]\ttrain-auc:0.718804\n",
      "[75]\ttrain-auc:0.720314\n",
      "[76]\ttrain-auc:0.721021\n",
      "[77]\ttrain-auc:0.722183\n",
      "[78]\ttrain-auc:0.723256\n",
      "[79]\ttrain-auc:0.724784\n",
      "[80]\ttrain-auc:0.725666\n",
      "[81]\ttrain-auc:0.726735\n",
      "[82]\ttrain-auc:0.728144\n",
      "[83]\ttrain-auc:0.729729\n",
      "[84]\ttrain-auc:0.730845\n",
      "[85]\ttrain-auc:0.732111\n",
      "[86]\ttrain-auc:0.733461\n",
      "[87]\ttrain-auc:0.734889\n",
      "[88]\ttrain-auc:0.735637\n",
      "[89]\ttrain-auc:0.73702\n",
      "[90]\ttrain-auc:0.738156\n",
      "[91]\ttrain-auc:0.739237\n",
      "[92]\ttrain-auc:0.740168\n",
      "[93]\ttrain-auc:0.741273\n",
      "[94]\ttrain-auc:0.742513\n",
      "[95]\ttrain-auc:0.743399\n",
      "[96]\ttrain-auc:0.744408\n",
      "[97]\ttrain-auc:0.745235\n",
      "[98]\ttrain-auc:0.746112\n",
      "[99]\ttrain-auc:0.747224\n",
      "[100]\ttrain-auc:0.748141\n",
      "[101]\ttrain-auc:0.749027\n",
      "[102]\ttrain-auc:0.749717\n",
      "[103]\ttrain-auc:0.750558\n",
      "[104]\ttrain-auc:0.751442\n",
      "[105]\ttrain-auc:0.752232\n",
      "[106]\ttrain-auc:0.7529\n",
      "[107]\ttrain-auc:0.75363\n",
      "[108]\ttrain-auc:0.754673\n",
      "[109]\ttrain-auc:0.755247\n",
      "[110]\ttrain-auc:0.755969\n",
      "[111]\ttrain-auc:0.756531\n",
      "[112]\ttrain-auc:0.757193\n",
      "[113]\ttrain-auc:0.757874\n",
      "[114]\ttrain-auc:0.758459\n",
      "[115]\ttrain-auc:0.759447\n",
      "[116]\ttrain-auc:0.760023\n",
      "[117]\ttrain-auc:0.760645\n",
      "[118]\ttrain-auc:0.76135\n",
      "[119]\ttrain-auc:0.761936\n",
      "[120]\ttrain-auc:0.762459\n",
      "[121]\ttrain-auc:0.763256\n",
      "[122]\ttrain-auc:0.764061\n",
      "[123]\ttrain-auc:0.764719\n",
      "[124]\ttrain-auc:0.765388\n",
      "[125]\ttrain-auc:0.765927\n",
      "[126]\ttrain-auc:0.76645\n",
      "[127]\ttrain-auc:0.766951\n",
      "[128]\ttrain-auc:0.767408\n",
      "[129]\ttrain-auc:0.768083\n",
      "[130]\ttrain-auc:0.768735\n",
      "[131]\ttrain-auc:0.769307\n",
      "[132]\ttrain-auc:0.770017\n",
      "[133]\ttrain-auc:0.770541\n",
      "[134]\ttrain-auc:0.771347\n",
      "[135]\ttrain-auc:0.772062\n",
      "[136]\ttrain-auc:0.772602\n",
      "[137]\ttrain-auc:0.772947\n",
      "[138]\ttrain-auc:0.77365\n",
      "[139]\ttrain-auc:0.774111\n",
      "[140]\ttrain-auc:0.774691\n",
      "[141]\ttrain-auc:0.775161\n",
      "[142]\ttrain-auc:0.775844\n",
      "[143]\ttrain-auc:0.776219\n",
      "[144]\ttrain-auc:0.776876\n",
      "[145]\ttrain-auc:0.777588\n",
      "[146]\ttrain-auc:0.777967\n",
      "[147]\ttrain-auc:0.77828\n",
      "[148]\ttrain-auc:0.778864\n",
      "[149]\ttrain-auc:0.779171\n",
      "[150]\ttrain-auc:0.779722\n",
      "[151]\ttrain-auc:0.780009\n",
      "[152]\ttrain-auc:0.780359\n",
      "[153]\ttrain-auc:0.780741\n",
      "[154]\ttrain-auc:0.78132\n",
      "[155]\ttrain-auc:0.781913\n",
      "[156]\ttrain-auc:0.782411\n",
      "[157]\ttrain-auc:0.783038\n",
      "[158]\ttrain-auc:0.783574\n",
      "[159]\ttrain-auc:0.783955\n",
      "[160]\ttrain-auc:0.78423\n",
      "[161]\ttrain-auc:0.784518\n",
      "[162]\ttrain-auc:0.784949\n",
      "[163]\ttrain-auc:0.78542\n",
      "[164]\ttrain-auc:0.78591\n",
      "[165]\ttrain-auc:0.786462\n",
      "[166]\ttrain-auc:0.787183\n",
      "[167]\ttrain-auc:0.787687\n",
      "[168]\ttrain-auc:0.788155\n",
      "[169]\ttrain-auc:0.788626\n",
      "[170]\ttrain-auc:0.789062\n",
      "[171]\ttrain-auc:0.789645\n",
      "[172]\ttrain-auc:0.790086\n",
      "[173]\ttrain-auc:0.790476\n",
      "[174]\ttrain-auc:0.791055\n",
      "[175]\ttrain-auc:0.791319\n",
      "[176]\ttrain-auc:0.791948\n",
      "[177]\ttrain-auc:0.792271\n",
      "[178]\ttrain-auc:0.792759\n",
      "[179]\ttrain-auc:0.793313\n",
      "[180]\ttrain-auc:0.793938\n",
      "[181]\ttrain-auc:0.794272\n",
      "[182]\ttrain-auc:0.794793\n",
      "[183]\ttrain-auc:0.795156\n",
      "[184]\ttrain-auc:0.795281\n",
      "[185]\ttrain-auc:0.795838\n",
      "[186]\ttrain-auc:0.79622\n",
      "[187]\ttrain-auc:0.79669\n",
      "[188]\ttrain-auc:0.797219\n",
      "[189]\ttrain-auc:0.797462\n",
      "[190]\ttrain-auc:0.797973\n",
      "[191]\ttrain-auc:0.798674\n",
      "[192]\ttrain-auc:0.799075\n",
      "[193]\ttrain-auc:0.799397\n",
      "[194]\ttrain-auc:0.799847\n",
      "[195]\ttrain-auc:0.800394\n",
      "[196]\ttrain-auc:0.800741\n",
      "[197]\ttrain-auc:0.801048\n",
      "[198]\ttrain-auc:0.801579\n",
      "[199]\ttrain-auc:0.801829\n",
      "[200]\ttrain-auc:0.802412\n",
      "[201]\ttrain-auc:0.802789\n",
      "[202]\ttrain-auc:0.803223\n",
      "[203]\ttrain-auc:0.803517\n",
      "[204]\ttrain-auc:0.803952\n",
      "[205]\ttrain-auc:0.804496\n",
      "[206]\ttrain-auc:0.80499\n",
      "[207]\ttrain-auc:0.805472\n",
      "[208]\ttrain-auc:0.805814\n",
      "[209]\ttrain-auc:0.806116\n",
      "[210]\ttrain-auc:0.806378\n",
      "[211]\ttrain-auc:0.806701\n",
      "[212]\ttrain-auc:0.807168\n",
      "[213]\ttrain-auc:0.807669\n",
      "[214]\ttrain-auc:0.808038\n",
      "[215]\ttrain-auc:0.808483\n",
      "[216]\ttrain-auc:0.808881\n",
      "[217]\ttrain-auc:0.809262\n",
      "[218]\ttrain-auc:0.809458\n",
      "[219]\ttrain-auc:0.809925\n",
      "[220]\ttrain-auc:0.810273\n",
      "[221]\ttrain-auc:0.810705\n",
      "[222]\ttrain-auc:0.810921\n",
      "[223]\ttrain-auc:0.811303\n",
      "[224]\ttrain-auc:0.811488\n",
      "[225]\ttrain-auc:0.811768\n",
      "[226]\ttrain-auc:0.812151\n",
      "[227]\ttrain-auc:0.812452\n",
      "[228]\ttrain-auc:0.812613\n",
      "[229]\ttrain-auc:0.813059\n",
      "[230]\ttrain-auc:0.813575\n",
      "[231]\ttrain-auc:0.813907\n",
      "[232]\ttrain-auc:0.814426\n",
      "[233]\ttrain-auc:0.814601\n",
      "[234]\ttrain-auc:0.814938\n",
      "[235]\ttrain-auc:0.815324\n",
      "[236]\ttrain-auc:0.81556\n",
      "[237]\ttrain-auc:0.815801\n",
      "[238]\ttrain-auc:0.816079\n",
      "[239]\ttrain-auc:0.816394\n",
      "[240]\ttrain-auc:0.816604\n",
      "[241]\ttrain-auc:0.816894\n",
      "[242]\ttrain-auc:0.817216\n",
      "[243]\ttrain-auc:0.817581\n",
      "[244]\ttrain-auc:0.817886\n",
      "[245]\ttrain-auc:0.81819\n",
      "[246]\ttrain-auc:0.818474\n",
      "[247]\ttrain-auc:0.81888\n",
      "[248]\ttrain-auc:0.819114\n",
      "[249]\ttrain-auc:0.819692\n",
      "[250]\ttrain-auc:0.819988\n",
      "[251]\ttrain-auc:0.820277\n",
      "[252]\ttrain-auc:0.820673\n",
      "[253]\ttrain-auc:0.82096\n",
      "[254]\ttrain-auc:0.821098\n",
      "[255]\ttrain-auc:0.821325\n",
      "[256]\ttrain-auc:0.821547\n",
      "[257]\ttrain-auc:0.821959\n",
      "[258]\ttrain-auc:0.822259\n",
      "[259]\ttrain-auc:0.822601\n",
      "[260]\ttrain-auc:0.822975\n",
      "[261]\ttrain-auc:0.823458\n",
      "[262]\ttrain-auc:0.823862\n",
      "[263]\ttrain-auc:0.824278\n",
      "[264]\ttrain-auc:0.824597\n",
      "[265]\ttrain-auc:0.824922\n",
      "[266]\ttrain-auc:0.825252\n",
      "[267]\ttrain-auc:0.825711\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(params, xgb_train, 268, watchlist,early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478035, 268)\n",
      "(18371, 268)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_leaves = model.predict(xgb_train, pred_leaf=True)\n",
    "test_leaves = model.predict(xgb_test, pred_leaf=True)\n",
    "(train_rows, cols) = train_leaves.shape\n",
    "    \n",
    "print(train_leaves.shape)\n",
    "print(test_leaves.shape)\n",
    "    \n",
    "del xgb_train,xgb_test,train,test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478035, 76)\n",
      "(18371, 76)\n"
     ]
    }
   ],
   "source": [
    "one_hot_train = utils.load_sparse_csr('onehot_train.npz')\n",
    "one_hot_test = utils.load_sparse_csr('onehot_test.npz')\n",
    "print(one_hot_train.shape)\n",
    "print(one_hot_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbdtenc = OneHotEncoder()\n",
    "trans = gbdtenc.fit_transform(np.concatenate((train_leaves, test_leaves), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_train = hstack([trans[:train_rows,:],one_hot_train])\n",
    "trans_test = hstack([trans[train_rows:,:],one_hot_test])\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 6.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0808350610736\n",
      "(18371, 13655)\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "lr = LogisticRegression(n_jobs=6,C=0.0004)\n",
    "    \n",
    "lr.fit(trans_train, train_label)\n",
    "    \n",
    "y_train_pred = lr.predict_proba(trans_train)[:,1]\n",
    "train_log = log_loss(train_label,y_train_pred)\n",
    "print(train_log)\n",
    "print(trans[train_rows:, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['predicted_score']= lr.predict_proba(trans_test)[:,1]\n",
    "df_test[['instance_id', 'predicted_score']].to_csv(PATH + 'xgboost_LR_baseline_1.txt',sep=\" \",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_sparse_csr('xgboost_onehot_train', trans[:train_rows,:])\n",
    "utils.save_sparse_csr('xgboost_onehot_test', trans[train_rows:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
